{"cells":[{"cell_type":"markdown","source":["# Writing Data\n\nJust as there are many ways to read data, we have just as many ways to write data.\n\nIn this notebook, we will take a quick peek at how to write data back out to Parquet files.\n\n**Technical Accomplishments:**\n- Writing data to Parquet files"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4971ae6c-e2aa-4988-9ed9-7a895c879471"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b1de67d-a252-4cd0-bf9b-0d1899d967f2"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbb6f8e0-6982-464f-b5bb-c106b38024fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Writing Data\n\nLet's start with one of our original CSV data sources, **pageviews_by_second.tsv**:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b4f69c1-8d26-42e6-96de-8c4ca042e522"}}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\ncsvSchema = StructType([\n  StructField(\"timestamp\", StringType(), False),\n  StructField(\"site\", StringType(), False),\n  StructField(\"requests\", IntegerType(), False)\n])\n\ncsvFile = \"/mnt/training/wikipedia/pageviews/pageviews_by_second.tsv\"\n\ncsvDF = (spark.read\n  .option('header', 'true')\n  .option('sep', \"\\t\")\n  .schema(csvSchema)\n  .csv(csvFile)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87a1addb-676c-4ab3-ad99-13754c33a7db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that we have a `DataFrame`, we can write it back out as Parquet files or other various formats."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22e8461f-292b-4d39-87b6-54afb5e71461"}}},{"cell_type":"code","source":["fileName = userhome + \"/pageviews_by_second.parquet\"\nprint(\"Output location: \" + fileName)\n\n(csvDF.write                       # Our DataFrameWriter\n  .option(\"compression\", \"snappy\") # One of none, snappy, gzip, and lzo\n  .mode(\"overwrite\")               # Replace existing files\n  .parquet(fileName)               # Write DataFrame to Parquet files\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfc442c8-d25d-4f3e-9e47-e18c4a590f5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that the file has been written out, we can see it in the DBFS:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"173b8e45-08fc-4a8b-a564-0f6860978b54"}}},{"cell_type":"code","source":["display(\n  dbutils.fs.ls(fileName)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81ab2d94-02b3-4d77-9a5c-7e07d32a5179"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And lastly we can read that same parquet file back in and display the results:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e4a807b-f014-4ab3-bc62-55dadbd32f26"}}},{"cell_type":"code","source":["display(\n  spark.read.parquet(fileName)\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc194c20-7d07-437d-afbe-7632e1037b5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Next steps\n\nStart the next lesson, [Reading Data - Lab]($./6.Reading%20Data%20-%20Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57fbaed8-42b9-4928-baaf-956bbfc9087f"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5.Writing Data","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3013059022293018}},"nbformat":4,"nbformat_minor":0}
